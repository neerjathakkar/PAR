# @package _global_

defaults:
    - launcher: default.yaml
    - trainer: default.yaml

callbacks:
    model_checkpoint:
        _target_: PAR.utils.ema_checkpoint.EMACheckpoint    
        dirpath: ${paths.output_dir}/checkpoints
        filename: "epoch_{epoch:03d}"
        monitor: "val/error/tx" #"val/mAP"
        mode: "min"
        save_last: True
        auto_insert_metric_name: False
        verbose: False # verbosity mode
        save_top_k: 1 # save k best models (determined by above metric)
        save_weights_only: False # if True, then only the modelâ€™s weights will be saved
        every_n_train_steps: null # number of training steps between checkpoints
        train_time_interval: null # checkpoints are monitored at the specified time interval
        every_n_epochs: 1 # number of epochs between checkpoints
        save_on_train_epoch_end: True # whether to run checkpointing at the end of the training epoch or the end of validation

    model_summary:
        _target_: lightning.pytorch.callbacks.RichModelSummary
        max_depth: 1

    rich_progress_bar:
        _target_: lightning.pytorch.callbacks.RichProgressBar
        refresh_rate: 1

    learning_rate_monitor:
        _target_: lightning.pytorch.callbacks.LearningRateMonitor

    timer:
        _target_: lightning.pytorch.callbacks.Timer
    
    ema:
      _target_: PAR.utils.ema.EMA
      decay: 0.99
      cpu_offload: False
      validate_original_weights: False
      every_n_steps: 1

logger:
    tensorboard:
        _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
        save_dir: "${paths.output_dir}/tensorboard/"
        version: 0
    
    wandb: 
        _target_: lightning.pytorch.loggers.wandb.WandbLogger
        save_dir: "${paths.output_dir}/tensorboard/"
        version: 0
        project: "par_dexycb"
        entity: "par"
        name: ${task_name}

paths: 
    root_dir: ${oc.env:PROJECT_ROOT}
    data_dir: ${paths.root_dir}/data/
    log_dir: ${paths.root_dir}/logs/
    output_dir: ${hydra:runtime.output_dir}
    work_dir: ${hydra:runtime.cwd}

extras:
    print_config: True

hydra:
    run:
        dir: ${paths.log_dir}/${task_name}
    sweep:
        dir: ${paths.log_dir}/${task_name}
        subdir: ${hydra.job.num}

hydra_logging: colorlog
job_logging: colorlog



# task name, determines output directory path
task_name: "1000"
tags: ["dev"]
# slrum_job_id: ${oc.env:SLURM_ARRAY_TASK_ID}

# set False to skip model training
train: True

# evaluate on test set, using best model weights achieved during training
# lightning chooses best weights based on the metric specified in checkpoint callback
test: True

# simply provide checkpoint path to resume training
ckpt_path: null

# seed for random number generators in pytorch, numpy and python.random
seed: 0


datamodule:
    _target_: PAR.datamodules.dexycb_datamodule.DexYCBDataModule
    cfg: ${configs}
    train: ${train}

model:
    _target_: PAR.models.dexycb_hand_prediction.PAR_LitModule
    cfg: ${configs}

configs:
    use_ln: True
    relative_norm: True
    rel_per_frame: True
    check_stdev: True
    obs_ratio: 0.5
    use_hand_loss: True
    pred_rot_only: False
    pred_tx_only: True
    data_dir: ${paths.data_dir}
    storage_folder: "${paths.log_dir}/${task_name}/${hydra:sweep.subdir}"
    train_dataset: ava_train,kinetics_train
    test_dataset: ava_val
    map_on: "AVA" # or "AVA-AK"
    train_batch_size: 8
    train_num_workers: 4
    test_batch_size: 1
    test_num_workers: 1
    test_class: ""
    test_batch_id: -1
    number_of_processes: 25
    pin_memory: True
    full_seq_render: False
    frame_length: 125
    num_agents: 2
    load_other_tracks: False
    img_size: 256
    load_images: False
    use_mean_std: True
    use_mean_std_mid: False
    frame_rate_range: 1
    num_smpl_heads: 1
    finetune: False
    bottle_neck: conv
    pos_embedding: learned
    mask_ratio: 0.4
    in_feat: 512
    one_euro_filter: "pred_loca,pred_pose"
    loss_type: "action_BCE"
    mask_type: "random"
    mask_type_test: "zero"
    test_type: "track.fullframe@" 
    encode_type: "4c"
    masked: False 
    weights_path: null
    loss_on_others_action: True
    debug: False
    load_strict: True
    use_cache: False
    lr_interval: "epoch"
    use_prefix_block_attention: False
    generate_social_translation: False
    do_vis: True
    loss_on_same_agent: False
    val_stride: 2
    loss_only_on_non_padded: False
    learnable_padding: False
    training_data_noise: 0 
    use_multiagent_pos_emb: True
    dropout_hidden: 0.0
    dropout_attn: 0.0
    quantize_preds: 0.0
    decay_teacher_forcing: False
    start_decay_epoch: 0 
    learned_timestep_embedding: False
    disable_rope: False
    map_only_on_ego: True
    use_bbox_emb: False
    
    mixed_training: 0

    compute_map: True
    compute_acc: True
    log_frequency: 10
    hmr_model: "hmr2018"
    loca_l1_weight: 1

    action_space: "ava"
    render_traj: False

    solver:
        name: "AdamW"
        lr: 0.0001
        momentum: 0.9
        decay_steps: [10,20]
        decay_gamma: 0.1
        layer_decay: null
        ZERO_WD_1D_PARAM: True
        warmup_epochs: 5
        weight_decay: 0.05
        scheduler: "cosine"
        apply_linear_scaling: True
    
    ava:
        sampling_factor: 1
        num_action_classes: 80
        num_valid_action_classes: 60
        gt_type: "all"
        head_dropout: 0.0
        predict_valid: True
        map_on: "AVA" # or "AVA-AK"

    kinetics:
        sampling_factor: 1
        num_action_classes: 400

    loss:
        focal:
            gamma: 2
            alpha: 0.25

    extra_feat: 
        enable: 'joints_3D,apperance'
        pose_shape:
            dim: 229
            mid_dim: 229
            en_dim: 128
        joints_3D:
            dim: 135
            mid_dim: 256
            en_dim: 128
        apperance:
            dim: 2048
            mid_dim: 512
            en_dim: 256

    transformer:
        model: legacy
        depth: 8
        heads: 8
        mlp_dim: 512
        dim_head: 64
        dropout: 0.1
        emb_dropout: 0.1
        droppath: 0.4
        use_interaction_module: False
        use_perceiver: False
        use_interaction_module_action_only: False
        hsize: 128
        isize: 128
        conv:
            pad: 1
            stride: 5